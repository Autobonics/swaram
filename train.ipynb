{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.optim as optim\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "from gloss_dataset import GlossDataset\n",
    "from gloss_model import GlossModel\n",
    "from torch.utils.tensorboard import SummaryWriter\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1596, 5)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get data for training\n",
    "gd = GlossDataset()\n",
    "input_size = gd[0][0].shape[1]\n",
    "class_no = len(gd.classes)\n",
    "input_size, class_no"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# provide input and class size\n",
    "model = GlossModel(input_size, class_no)\n",
    "device = model.device\n",
    "model.to(device)\n",
    "optim = optim.Adam(model.parameters(), lr=1e-4)\n",
    "loss_fn = nn.CrossEntropyLoss()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NVIDIA GeForce GTX 1650\n"
     ]
    }
   ],
   "source": [
    "if torch.cuda.is_available():\n",
    "    print(torch.cuda.get_device_name(device=device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize sumamry writer\n",
    "writer=SummaryWriter()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create testing and training dataLoader from single dataset using random_split\n",
    "# and also set training epoch\n",
    "split_ratio = 0.8\n",
    "batch_size = 1\n",
    "train_size = int(split_ratio*len(gd))\n",
    "test_size = len(gd)-train_size\n",
    "train_data, test_data = random_split(gd, [train_size, test_size])\n",
    "train_dl = DataLoader(train_data, batch_size=batch_size,\n",
    "                      shuffle=True, pin_memory=False)\n",
    "test_dl = DataLoader(test_data, batch_size=batch_size,\n",
    "                     shuffle=True, pin_memory=False)\n",
    "epoch = 1000\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000, Loss: 1.6105\n",
      "Epoch 11/1000, Loss: 1.6043\n",
      "Epoch 21/1000, Loss: 1.5990\n",
      "Epoch 31/1000, Loss: 1.6035\n",
      "Epoch 41/1000, Loss: 1.5731\n",
      "Epoch 51/1000, Loss: 1.5511\n",
      "Epoch 61/1000, Loss: 1.5939\n",
      "Epoch 71/1000, Loss: 1.5557\n",
      "Epoch 81/1000, Loss: 1.4914\n",
      "Epoch 91/1000, Loss: 1.4598\n",
      "Epoch 101/1000, Loss: 1.4496\n",
      "Epoch 111/1000, Loss: 1.4073\n",
      "Epoch 121/1000, Loss: 1.3845\n",
      "Epoch 131/1000, Loss: 1.3656\n",
      "Epoch 141/1000, Loss: 1.3509\n",
      "Epoch 151/1000, Loss: 1.3394\n",
      "Epoch 161/1000, Loss: 1.4267\n",
      "Epoch 171/1000, Loss: 1.3260\n",
      "Epoch 181/1000, Loss: 1.3136\n",
      "Epoch 191/1000, Loss: 1.3085\n",
      "Epoch 201/1000, Loss: 1.3043\n",
      "Epoch 211/1000, Loss: 1.3012\n",
      "Epoch 221/1000, Loss: 1.3702\n",
      "Epoch 231/1000, Loss: 1.2989\n",
      "Epoch 241/1000, Loss: 1.2939\n",
      "Epoch 251/1000, Loss: 1.3570\n",
      "Epoch 261/1000, Loss: 1.2889\n",
      "Epoch 271/1000, Loss: 1.2837\n",
      "Epoch 281/1000, Loss: 1.2850\n",
      "Epoch 291/1000, Loss: 1.2572\n",
      "Epoch 301/1000, Loss: 1.2644\n",
      "Epoch 311/1000, Loss: 1.2392\n",
      "Epoch 321/1000, Loss: 1.2365\n",
      "Epoch 331/1000, Loss: 1.4237\n",
      "Epoch 341/1000, Loss: 1.2206\n",
      "Epoch 351/1000, Loss: 1.2240\n",
      "Epoch 361/1000, Loss: 1.1690\n",
      "Epoch 371/1000, Loss: 1.1480\n",
      "Epoch 381/1000, Loss: 1.1907\n",
      "Epoch 391/1000, Loss: 1.2321\n",
      "Epoch 401/1000, Loss: 1.1394\n",
      "Epoch 411/1000, Loss: 1.1721\n",
      "Epoch 421/1000, Loss: 1.2042\n",
      "Epoch 431/1000, Loss: 1.0758\n",
      "Epoch 441/1000, Loss: 1.0789\n",
      "Epoch 451/1000, Loss: 1.0545\n",
      "Epoch 461/1000, Loss: 1.1280\n",
      "Epoch 471/1000, Loss: 1.0602\n",
      "Epoch 481/1000, Loss: 1.0543\n",
      "Epoch 491/1000, Loss: 1.1097\n",
      "Epoch 501/1000, Loss: 1.0192\n",
      "Epoch 511/1000, Loss: 1.0239\n",
      "Epoch 521/1000, Loss: 1.1011\n",
      "Epoch 531/1000, Loss: 0.9945\n",
      "Epoch 541/1000, Loss: 0.9870\n",
      "Epoch 551/1000, Loss: 1.0752\n",
      "Epoch 561/1000, Loss: 1.2606\n",
      "Epoch 571/1000, Loss: 1.0472\n",
      "Epoch 581/1000, Loss: 0.9820\n",
      "Epoch 591/1000, Loss: 0.9706\n",
      "Epoch 601/1000, Loss: 0.9668\n",
      "Epoch 611/1000, Loss: 0.9647\n",
      "Epoch 621/1000, Loss: 0.9630\n",
      "Epoch 631/1000, Loss: 0.9614\n",
      "Epoch 641/1000, Loss: 0.9601\n",
      "Epoch 651/1000, Loss: 1.3371\n",
      "Epoch 661/1000, Loss: 0.9859\n",
      "Epoch 671/1000, Loss: 0.9600\n",
      "Epoch 681/1000, Loss: 1.0551\n",
      "Epoch 691/1000, Loss: 1.2356\n",
      "Epoch 701/1000, Loss: 0.9612\n",
      "Epoch 711/1000, Loss: 0.9757\n",
      "Epoch 721/1000, Loss: 0.9827\n",
      "Epoch 731/1000, Loss: 0.9827\n",
      "Epoch 741/1000, Loss: 1.1433\n",
      "Epoch 751/1000, Loss: 1.1430\n",
      "Epoch 761/1000, Loss: 1.1427\n",
      "Epoch 771/1000, Loss: 1.1413\n",
      "Epoch 781/1000, Loss: 1.0249\n",
      "Epoch 791/1000, Loss: 0.9847\n",
      "Epoch 801/1000, Loss: 0.9833\n",
      "Epoch 811/1000, Loss: 0.9828\n",
      "Epoch 821/1000, Loss: 1.0962\n",
      "Epoch 831/1000, Loss: 0.9820\n",
      "Epoch 841/1000, Loss: 0.9705\n",
      "Epoch 851/1000, Loss: 1.1983\n",
      "Epoch 861/1000, Loss: 1.1421\n",
      "Epoch 871/1000, Loss: 1.1400\n",
      "Epoch 881/1000, Loss: 0.9753\n",
      "Epoch 891/1000, Loss: 0.9873\n",
      "Epoch 901/1000, Loss: 1.0251\n",
      "Epoch 911/1000, Loss: 0.9699\n",
      "Epoch 921/1000, Loss: 0.9696\n",
      "Epoch 931/1000, Loss: 0.9817\n",
      "Epoch 941/1000, Loss: 0.9584\n",
      "Epoch 951/1000, Loss: 1.1410\n",
      "Epoch 961/1000, Loss: 0.9830\n",
      "Epoch 971/1000, Loss: 0.9745\n",
      "Epoch 981/1000, Loss: 1.0043\n",
      "Epoch 991/1000, Loss: 0.9881\n"
     ]
    }
   ],
   "source": [
    "# Start model training\n",
    "model.train()\n",
    "for i in range(epoch):\n",
    "    total_loss=0\n",
    "    for x_train, y_train in train_dl:\n",
    "        xtrain, y_train = x_train.to(device), y_train.to(device)\n",
    "        out = model(x_train)\n",
    "        loss = loss_fn(out, y_train.argmax(dim=1))\n",
    "        optim.zero_grad()\n",
    "        loss.backward()\n",
    "        optim.step()\n",
    "        total_loss += loss.item()\n",
    "    \n",
    "    avg_loss = total_loss / len(train_dl)\n",
    "    writer.add_scalar(\"Loss/epoch\", avg_loss, i)\n",
    "\n",
    "    if (i % 10 == 0):\n",
    "        print(f\"Epoch {i+1}/{epoch}, Loss: {avg_loss:.4f}\")\n",
    "\n",
    "writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Acc 0.7500\n",
      "Test Loss : 1.1538\n",
      "\n",
      "Total test samples :  20\n",
      "Correct predictions :  15\n"
     ]
    }
   ],
   "source": [
    "# Evaluate Test set\n",
    "model.eval()\n",
    "tot_loss = 0\n",
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for x_test, y_test in test_dl:\n",
    "        out = model(x_test)\n",
    "        y_test=y_test.argmax(dim=1)\n",
    "        loss = loss_fn(out, y_test)\n",
    "        tot_loss += loss.item()\n",
    "        y_pred = torch.argmax(out, dim=1)\n",
    "        correct += torch.sum(torch.eq(y_pred, y_test)).item()\n",
    "        total += y_test.shape[0]\n",
    "\n",
    "acc = correct / total\n",
    "loss = tot_loss / len(test_dl)\n",
    "print(f\"Test Acc {acc:.4f}\\nTest Loss : {loss:.4f}\\n\")\n",
    "print(\"Total test samples : \", total)\n",
    "print(\"Correct predictions : \", correct)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the model\n",
    "torch.save(model, \"swaram_lstm.pt\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "swaram-venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
