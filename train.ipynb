{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.optim as optim\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "from gloss_dataset import GlossDataset\n",
    "from gloss_model import GlossModel\n",
    "from torch.utils.tensorboard import SummaryWriter\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1596, 4)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get data for training\n",
    "gd = GlossDataset()\n",
    "input_size = gd[0][0].shape[1]\n",
    "class_no = len(gd.classes)\n",
    "input_size, class_no"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GlossModel(\n",
       "  (softmax): Softmax(dim=1)\n",
       "  (sigmoid): Sigmoid()\n",
       "  (lstm1): LSTM(1596, 128, batch_first=True)\n",
       "  (dropout1): Dropout(p=0.15, inplace=False)\n",
       "  (lstm2): LSTM(128, 64, batch_first=True)\n",
       "  (dropout2): Dropout(p=0.15, inplace=False)\n",
       "  (fc1): Linear(in_features=64, out_features=32, bias=True)\n",
       "  (dropout3): Dropout(p=0.15, inplace=False)\n",
       "  (fc2): Linear(in_features=32, out_features=4, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# provide input and class size\n",
    "model = GlossModel(input_size, class_no)\n",
    "model.to(model.device)\n",
    "optim = optim.Adam(model.parameters(), lr=1e-4)\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize sumamry writer\n",
    "writer=SummaryWriter()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create testing and training dataLoader from single dataset using random_split\n",
    "# and also set training epoch\n",
    "split_ratio = 0.8\n",
    "batch_size = 1\n",
    "train_size = int(split_ratio*len(gd))\n",
    "test_size = len(gd)-train_size\n",
    "train_data, test_data = random_split(gd, [train_size, test_size])\n",
    "train_dl = DataLoader(train_data, batch_size=batch_size, shuffle=True)\n",
    "test_dl = DataLoader(test_data, batch_size=batch_size, shuffle=True)\n",
    "epoch = 4000\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss/epoch : (3.8705081939697266, 0)\n",
      "Loss/epoch : (3.8001532554626465, 100)\n",
      "Loss/epoch : (3.3649535179138184, 200)\n",
      "Loss/epoch : (3.172327995300293, 300)\n",
      "Loss/epoch : (3.1654043197631836, 400)\n",
      "Loss/epoch : (3.161846160888672, 500)\n",
      "Loss/epoch : (3.157863140106201, 600)\n",
      "Loss/epoch : (3.157156229019165, 700)\n",
      "Loss/epoch : (3.157242774963379, 800)\n",
      "Loss/epoch : (3.1571006774902344, 900)\n",
      "Loss/epoch : (3.157226800918579, 1000)\n",
      "Loss/epoch : (3.156790018081665, 1100)\n",
      "Loss/epoch : (3.156585693359375, 1200)\n",
      "Loss/epoch : (3.1563987731933594, 1300)\n",
      "Loss/epoch : (3.156470775604248, 1400)\n",
      "Loss/epoch : (3.156411647796631, 1500)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 8\u001b[0m\n\u001b[0;32m      6\u001b[0m     out \u001b[39m=\u001b[39m model(x_train\u001b[39m.\u001b[39mto(model\u001b[39m.\u001b[39mdevice))\n\u001b[0;32m      7\u001b[0m     loss \u001b[39m=\u001b[39m loss_fn(out, y_train\u001b[39m.\u001b[39mto(model\u001b[39m.\u001b[39mdevice))\n\u001b[1;32m----> 8\u001b[0m     loss\u001b[39m.\u001b[39;49mbackward()\n\u001b[0;32m      9\u001b[0m     optim\u001b[39m.\u001b[39mstep()\n\u001b[0;32m     10\u001b[0m writer\u001b[39m.\u001b[39madd_scalar(\u001b[39m\"\u001b[39m\u001b[39mLoss/epoch\u001b[39m\u001b[39m\"\u001b[39m, loss\u001b[39m.\u001b[39mitem(), i)\n",
      "File \u001b[1;32mc:\\Users\\rv1n\\Desktop\\test\\swaram\\swaram-venv\\lib\\site-packages\\torch\\_tensor.py:487\u001b[0m, in \u001b[0;36mTensor.backward\u001b[1;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[0;32m    477\u001b[0m \u001b[39mif\u001b[39;00m has_torch_function_unary(\u001b[39mself\u001b[39m):\n\u001b[0;32m    478\u001b[0m     \u001b[39mreturn\u001b[39;00m handle_torch_function(\n\u001b[0;32m    479\u001b[0m         Tensor\u001b[39m.\u001b[39mbackward,\n\u001b[0;32m    480\u001b[0m         (\u001b[39mself\u001b[39m,),\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    485\u001b[0m         inputs\u001b[39m=\u001b[39minputs,\n\u001b[0;32m    486\u001b[0m     )\n\u001b[1;32m--> 487\u001b[0m torch\u001b[39m.\u001b[39;49mautograd\u001b[39m.\u001b[39;49mbackward(\n\u001b[0;32m    488\u001b[0m     \u001b[39mself\u001b[39;49m, gradient, retain_graph, create_graph, inputs\u001b[39m=\u001b[39;49minputs\n\u001b[0;32m    489\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\rv1n\\Desktop\\test\\swaram\\swaram-venv\\lib\\site-packages\\torch\\autograd\\__init__.py:200\u001b[0m, in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[0;32m    195\u001b[0m     retain_graph \u001b[39m=\u001b[39m create_graph\n\u001b[0;32m    197\u001b[0m \u001b[39m# The reason we repeat same the comment below is that\u001b[39;00m\n\u001b[0;32m    198\u001b[0m \u001b[39m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[0;32m    199\u001b[0m \u001b[39m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[1;32m--> 200\u001b[0m Variable\u001b[39m.\u001b[39;49m_execution_engine\u001b[39m.\u001b[39;49mrun_backward(  \u001b[39m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[0;32m    201\u001b[0m     tensors, grad_tensors_, retain_graph, create_graph, inputs,\n\u001b[0;32m    202\u001b[0m     allow_unreachable\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m, accumulate_grad\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Start model training\n",
    "model.train()\n",
    "for i in range(epoch+1):\n",
    "    for x_train, y_train in train_dl:\n",
    "        optim.zero_grad()\n",
    "        out = model(x_train.to(model.device))\n",
    "        loss = loss_fn(out, y_train.to(model.device))\n",
    "        loss.backward()\n",
    "        optim.step()\n",
    "    writer.add_scalar(\"Loss/epoch\", loss.item(), i)\n",
    "    if (i % 100 == 0):\n",
    "        print(f\"Loss/epoch : {loss.item(),i}\")\n",
    "    writer.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate Test set\n",
    "model.eval()\n",
    "tot_loss = 0\n",
    "tp = 0\n",
    "tot_test = 0\n",
    "with torch.no_grad():\n",
    "    for x_test, y_test in test_dl:\n",
    "        out = model(x_test)\n",
    "        loss = loss_fn(out, y_train)\n",
    "        tot_loss += loss\n",
    "        y_pred = torch.argmax(out[2])\n",
    "        y_test = torch.argmax(y_test)\n",
    "        if y_pred == y_test:\n",
    "            tp += 1\n",
    "        tot_test += 1\n",
    "\n",
    "# Much more data required for training and test set\n",
    "acc = tp/tot_test\n",
    "loss = tot_loss/tot_test\n",
    "print(f\"Test Acc {acc}\\nTest Loss : {loss}\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the model\n",
    "torch.save(model, \"swaram_lstm.pt\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "swaram-venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
